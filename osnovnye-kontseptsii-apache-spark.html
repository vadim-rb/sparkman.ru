<!DOCTYPE html>
<html lang="ru">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Vadim" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="spark, theory, Apache Spark, " />

<meta property="og:title" content="Основные концепции Apache Spark "/>
<meta property="og:url" content="/osnovnye-kontseptsii-apache-spark.html" />
<meta property="og:description" content="RDD - базовая концепция Spark Ключом к пониманию Apache Spark является RDD - Resilient Distributed Dataset(устойчивый распределенный набор данных). RDD содержит произвольную коллекцию объектов. Каждый набор данных в RDD распределяется между узлами кластера, чтобы их можно было обрабатывать параллельно. RDD неизменяемы — их нельзя изменить после создания и распространения по кластеру. Физически …" />
<meta property="og:site_name" content="sparkman.ru" />
<meta property="og:article:author" content="Vadim" />
<meta property="og:article:published_time" content="2024-12-03T10:20:00+03:00" />
<meta name="twitter:title" content="Основные концепции Apache Spark ">
<meta name="twitter:description" content="RDD - базовая концепция Spark Ключом к пониманию Apache Spark является RDD - Resilient Distributed Dataset(устойчивый распределенный набор данных). RDD содержит произвольную коллекцию объектов. Каждый набор данных в RDD распределяется между узлами кластера, чтобы их можно было обрабатывать параллельно. RDD неизменяемы — их нельзя изменить после создания и распространения по кластеру. Физически …">

        <title>Основные концепции Apache Spark  · sparkman.ru
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="/"><span class=site-name>sparkman.ru</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       "/"
                                    >Home</a>
                                </li>
                                <li ><a href="/categories.html">Categories</a></li>
                                <li ><a href="/tags.html">Tags</a></li>
                                <li ><a href="/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="/osnovnye-kontseptsii-apache-spark.html">
                Основные концепции Apache Spark
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <h1>RDD - базовая концепция Spark</h1>
<p>Ключом к пониманию Apache Spark является RDD - Resilient Distributed Dataset(устойчивый распределенный набор данных).
RDD содержит произвольную коллекцию объектов.
Каждый набор данных в RDD распределяется между узлами кластера, чтобы их можно было обрабатывать параллельно.
RDD неизменяемы — их нельзя изменить после создания и распространения по кластеру.<br>
Физически RDD хранится как объект JVM на драйвере и ссылается на данные, хранящиеся либо в постоянном хранилище
(HDFS, S3, PostgreSQL и т. д.), либо в кэше (память, память+диск, только диск и т. д.), либо на другом RDD.<br>
<strong>Если сказать прямо, то Apache Spark — это просто реализация RDD.</strong><br>
<em>Пример RDD:</em><br>
<img alt="RDD image 1" src="/images/rdd.drawio.png"><br>
RDD хранит следующие метаданные:  </p>
<ul>
<li><strong>Partitions</strong> - набор партиций данных, связанных с этим RDD. 
Они расположены на узлах кластера. Одна партиция- минимальная партия данных,
которая может быть обработана каждым узлом кластера;</li>
<li><strong>Dependencies</strong> - список родительских RDD, участвующих в вычислении, так называемый линейный граф;</li>
<li><strong>Computation</strong> - функция для вычисления дочерних RDD из родительских RDD;</li>
<li><strong>Preferred Locations</strong> - где лучше всего разместить вычисления по разделам (локальность данных);</li>
<li><strong>Partitioner</strong> - как данные делятся на разделы (по умолчанию они делятся с помощью HashPartitioner);</li>
</ul>
<p>При сбое RDD может быть воссоздан, поскольку каждый RDD знает, как он был создан
(благодаря хранению линейного графа). 
Кроме того, RDD могут быть материализованы, в памяти или на диске.<br>
<em>Пример RDD pyspark:</em><br>
<img alt="RDD image 2" src="/images/rdd.PNG"><br>
RDD также можно кэшировать и разбивать вручную. Кэширование полезно, когда мы используем определенный
RDD несколько. А ручное разбиение важно для правильной балансировки данных между партициями.<br>
<em>Проверим количество партиций и данных в них:</em><br>
<img alt="RDD image 3" src="/images/rdd2.PNG">  </p>
<h2>Почему RDD неизменяемы?</h2>
<p>На это есть несколько причин:  </p>
<ul>
<li><strong>Влияние функционального программирования</strong> - Apache Spark разработан с сильным влиянием парадигмы 
функционального программирования. Функциональное программирование подчеркивает неизменяемость и чистые функции.</li>
<li><strong>Поддержка одновременного потребления</strong> - RDD предназначены для поддержки параллельной обработки данных. В распределенной среде, где несколько узлов могут получать доступ к данным и обрабатывать их
одновременно, неизменяемость становится критически важной. Неизменяемые структуры данных гарантируют, что данные остаются согласованными между потоками, 
устраняя необходимость в сложных механизмах синхронизации и снижая риск возникновения условий гонки.
Каждое преобразование создает новый RDD, устраняя риск возникновения условий гонки и обеспечивая целостность данных.</li>
<li><strong>Вычисления в оперативной памяти</strong> - Apache Spark известен своей способностью выполнять вычисления в памяти, что значительно повышает производительность. Хранение данных в памяти обеспечивает высокоскоростной доступ к ним, и неизменяемость играет здесь ключевую роль. Неизменяемые структуры данных устраняют необходимость частой инвалидации кэша(процесс удаления данных кэша, которые больше не являются действительными или актуальными), что упрощает поддержание согласованности и надежности в высокопроизводительной вычислительной среде.</li>
<li><strong>Линейность и отказоустойчивость</strong> - Resilient(Устойчивый) в RDD означает способность быстро восстанавливаться после сбоев. Такая устойчивость очень важна для распределенных вычислений, где сбои могут происходить относительно часто. RDD обеспечивают отказоустойчивость с помощью линейного графа (или информации о линейном графе). Линейный граф - это возможность восстановить потерянный или поврежденный RDD, проследив историю его преобразований. Поскольку RDD неизменяемы, они обеспечивают детерминированный способ восстановления предыдущего шага даже после сбоя. Эта функция отслеживания истории очень важна для обеспечения отказоустойчивости и восстановления данных в Spark. Если бы RDD были изменяемыми, было бы сложно восстанавливать предыдущее состояние в случае сбоев узлов. Неизменяемость обеспечивает сохранность информации о состоянии и позволяет Spark надежно восстанавливать потерянные данные.</li>
</ul>
<h2>Трансформации и действия</h2>
<p>Все самое интересное, что происходит в Spark, происходит через операции с RDD. То есть обычно приложения Spark выглядят следующим образом - мы создаем RDD (например, читаем данные в виде файла из HDFS), трансформируем их (map, reduce, join, groupBy, aggregate, reduce, ...), делаем что-то с результатом (например, сбрасываем его обратно в HDFS). <br>
<img alt="image" src="/images/ta.drawio.png"><br>
С помощью RDD можно выполнять два типа операций над RDD (и, соответственно, вся работа с данными происходит в последовательном выполнении цепочки из этих двух типов): трансформации(transformations) и действия(actions).  </p>
<h3>Трансформации</h3>
<p>Результатом применения этого типа операции к RDD является новый RDD. Как правило, это операции, которые каким-то образом преобразуют элементы данных.
Трансформации по своей природе ленивы(lazy) (еще их называют отложенными), то есть когда мы вызываем какую-то операцию над RDD, она не выполняется немедленно. Spark хранит запись о том, какая операция была вызвана (используя DAG).
Благодаря  трансформациям мы можем начать выполнение операций в любой момент, вызвав действие над RDD. Следовательно, данные не загружаются до тех пор, пока они не понадобятся, пока не вызовется действие. Это дает широкие возможности для низкоуровневых оптимизаций.
Существуют две группы трансформаций, а именно:</p>
<ul>
<li>узкие трансформации(narrow transformations)</li>
<li>широкие трансформации (wide transformations).</li>
</ul>
<p><img alt="image" src="/images/narrow-wide.drawio.png"><br>
Узкая трансформации не требует перемешивания(shuffle) или реорганизации данных между партициями. Пример таких трансформаций это  map, filter и т. д.<br>
Перемешивание происходит при перегруппировке данных между партициями. Это необходимо, когда для преобразования требуется информация из других партиций, например суммирование всех значений в столбце. Spark соберет необходимые данные из каждой партиции и объединит их в новую партицию. Перемешивание почти всегда вызывает сетевой обмен данными между экзекьюторами и соответственно узлами кластера, что является очень ресурсоемкой операцией.<br>
<strong>Посмотрим на узкую трансформацию filter:</strong><br>
<img alt="image" src="/images/narrow1.PNG"><br>
В этом примере , каждая партиция может быть обработана независимо от другой партиции.<br>
При широкой трансформации (groupByKey, join и т. д.) данные, необходимые для обработки, могут находиться в нескольких партициях родительского RDD, которые необходимо объединить. Для реализации этих операций Spark должен выполнить перетасовку, перемещая данные по кластеру и формируя новый RDD с новым набором партиций(широкие трансформации могут изменить количество партиций), как показано в примере ниже:<br>
<img alt="image" src="/images/wide1.PNG"><br>
Узкие трансформации не только более эффективны с точки зрения производительности, так как не предполагают сетевой передачи данных (а также подготовки к ней, включающей работу с диском и сериализацию), но и более надежны в ситуациях утраты части данных.  </p>
<h3>Действия</h3>
<p>Действия применяются, когда необходимо материализовать результат - сохранить данные на диск, записать их в базу данных или вывести часть данных на консоль. Операция collect, которую мы использовали, также является действием.<br>
Действия не являются ленивыми(lazy) - они сразу запускают обработку данных(создают job ‘ы). Действия - это операции RDD, которые производят значения, не являющиеся RDD.
<strong>Например, чтобы получить кол-во элементов в RDD, мы можем использовать действие count:</strong><br>
<img alt="image" src="/images/rdd3.PNG">  </p>
<h2>DAG</h2>
<p>DAG (Directed Acyclic Graph Направленный Ациклический Граф) в Spark— это фундаментальная концепция, которая играет важную роль в модели выполнения Spark. DAG является «направленным», поскольку операции выполняются в определенном порядке, и «ацикличным», поскольку в плане выполнения нет циклов или петель. Это означает, что каждый этап зависит от завершения предыдущего этапа, и каждая задача на этапе может выполняться независимо от другой.<br>
Непосредственно запуском вычислений над данными в Spark управляет DAGScheduler, находящийся в драйвере приложения. DAGScheduler отвечает за: </p>
<ul>
<li>создание выполняемого графа приложения;</li>
<li>генерацию задач, назначение и их рассылку на экзекьютеры;</li>
<li>мониторинг хода их выполнения;</li>
<li>отслеживание событий отказа и принятие решения о перезапуске или остановке вычислений;</li>
</ul>
<p>Материализованная форма графа состоит из стадий (stage). Стадия представляет собой последовательность RDD, связанных узкими трансформациями. Результатом такой стадии является либо сетевой обмен данными между executor’ами и соответственно узлами кластера(shuffle), либо сохранение результатов во внешнее хранилище, либо, в определенных случаях, возвращение данных в драйвер приложения (collect). Объединение функций обработки по узким  трансформациям позволяет не генерировать промежуточных наборов данных и таким образом избежать ненужных накладных расходов на запись на диск данных, их сериализацию / десериализацию.<br>
<img alt="image" src="/images/dag.drawio.png">  </p>


             
 
            
            
            






            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-12-03T10:20:00+03:00">дек 3, 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#apache-spark-ref">Apache Spark</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="/tags.html#spark-ref">spark
                    <span>1</span>
</a></li>
                <li><a href="/tags.html#theory-ref">theory
                    <span>1</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
</div>
            





            





        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>